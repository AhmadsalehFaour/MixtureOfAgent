# ğŸ§  MoA: Mixture of Agents

<p align="center">
  <img src="https://img.shields.io/badge/AI-Mixture_of_Agents-blue?style=for-the-badge&logo=openai" />
  <img src="https://img.shields.io/badge/Framework-Streamlit-red?style=for-the-badge&logo=streamlit" />
  <img src="https://img.shields.io/badge/Models-HuggingFace-orange?style=for-the-badge&logo=huggingface" />
  <img src="https://img.shields.io/badge/Docker-Ready-green?style=for-the-badge&logo=docker" />
</p>

---

## ğŸ¯ Project Idea

**MoA (Mixture of Agents)** is an application that combines multiple AI models (Proposers & Aggregator) to generate a unified, more accurate response.  
Users can enter any question, receive two answers from different models, and then the **Aggregator agent** merges them into a simplified final answer.

---

## ğŸ“Š Why is this field important?

```
  +----------------------+       +----------------------+
  |   ğŸ¤– Proposer 1      |       |   ğŸ¤– Proposer 2      |
  | (LLM / Transformer)  |       | (LLM / Seq2Seq)      |
  +----------+-----------+       +-----------+----------+
             |                           |
             +------------+--------------+
                          |
                  ğŸ”€ Aggregator Agent
                          |
                 âœ… Final Unified Response
```

- ğŸ§© **Model integration**: leverage the strengths of each model.  
- ğŸ“š **More accurate answers**: reduce bias and mistakes from a single model.  
- ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ **Accessible to everyone**: outputs are simplified, even for kids.  
- ğŸš€ **High flexibility**: supports both local (Ollama) and remote (HuggingFace) execution.  

---

## âš™ï¸ Core Components

- **`main.py`**: Streamlit-powered interactive UI.  
- **`logic.py`**: Logic for generating and aggregating answers.  
- **`utils.py`**: Logging and prompt saving.  
- **`models.py`**: Load models (local & remote).  
- **`docker-compose.yml` + `Dockerfile`**: Run the project in containers.  
- **`.env`**: Environment variables (e.g., HF_TOKEN).  
- **`requirements.txt`**: Dependencies (Torch, Transformers, Streamlit).  
- **`FUTURE_ENHANCEMENTS.md`**: Roadmap for upcoming features.  

---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Run locally
```bash
git clone https://github.com/AhmadsalehFaour/moa.git
cd moa
pip install -r requirements.txt
streamlit run main.py
```

### 2ï¸âƒ£ Run with Docker
```bash
docker-compose up --build
```

---

## ğŸŒ Modes

- ğŸ›°ï¸ **Remote Mode** â†’ Cloud models (Falcon, Flan-T5).  
- ğŸ’» **Local Mode** â†’ Local Ollama models (llama3, qwen, deepseek).  

---

## ğŸ“Œ Demo Screenshots

<p align="center">
  <img src="https://via.placeholder.com/800x400.png?text=Streamlit+UI+Demo" alt="Demo Screenshot" />
</p>

---

## ğŸ§® Future Roadmap

- Support **LangChain** and **RAG** for external knowledge.  
- **Multilingual interface**.  
- Export sessions to **CSV / JSON**.  
- Deployment to **HuggingFace Spaces**.  

---

## ğŸ‘¨â€ğŸ’» Contributors

- **Mixture of Agents** development team.  
- Open contributions from the community via Pull Requests.  

---

## ğŸ“œ License

This project is open-source under the **MIT License**.
